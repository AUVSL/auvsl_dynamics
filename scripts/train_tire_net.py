import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torch.autograd as autograd


import pandas as pd
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import mean_squared_error
from sklearn.utils import shuffle
from scipy.spatial.transform import Rotation
import matplotlib.pyplot as plt

from pickle import load
from pickle import dump

global count
#import pdb; pdb.set_trace() #this is completely overpowered. Too useful.



input_scaler = StandardScaler()
output_scaler = StandardScaler()


def print_c_network(md, input_scaler, output_scaler):
  output = "//#include \"solver.h\"\n//Auto Generated by pretrain.py\n\nvoid Solver::load_nn_gc_model(){\n"
  torch.set_printoptions(threshold=10000)
  for c in md.keys():
    temp = str(c)
    name = temp[2:] + temp[0]
    output += ((str(md[c].flatten()).replace("tensor([", name + " << ").replace("])", ";")) + "\n")
  
  output += "out_mean " + str(output_scaler.mean_.tolist()).replace("[","<< ").replace("]", ";") + "\n"
  output += "out_std " + str(np.sqrt(output_scaler.var_).tolist()).replace("[","<< ").replace("]", ";") + "\n"
  
  output += "in_mean " + str(input_scaler.mean_.tolist()).replace("[","<< ").replace("]", ";") + "\n"
  output += "in_std " + str(np.sqrt(input_scaler.var_).tolist()).replace("[","<< ").replace("]", ";") + "\n"
  
  output += "}"
  #print(output)
  with open('solver_nn_gc.cpp','w') as f:
    f.write(output)
  return


def process_data():
    in_features = ['zr','slip_ratio','slip_angle', 'kc','kphi','n0','n1','phi']
    out_features = ['Fx','Fy','Fz', 'Ty']
    
    df = pd.read_csv("../data/f_tire_train.csv")
    
    data_x = np.array(df[in_features])
    data_y = np.array(df[out_features])
    
    
    
    data_x = input_scaler.fit_transform(data_x)
    data_y = output_scaler.fit_transform(data_y)
    
    data_len = data_x.shape[0]
    
    train_data = data_x[:int(data_len*.95),:]
    label_data = data_y[:int(data_len*.95),:]
    
    train_data, label_data = shuffle(train_data, label_data, random_state=1)    
    
    test_data = data_x[int(data_len*.95):,:]
    test_labels = data_y[int(data_len*.95):,:]
    
    
    np.save("../data/train_data", train_data)
    np.save("../data/label_data", label_data)

    np.save("../data/test_data", test_data)
    np.save("../data/test_labels", test_labels)
    
    dump(input_scaler, open('../data/input_scaler.pkl', 'wb'))
    dump(output_scaler, open('../data/output_scaler.pkl', 'wb'))
    




#torch.cuda.init()
#torch.cuda.set_device(0)

print("processing data")
process_data()
print("done processing data")


train_data = np.load("../data/train_data.npy")
label_data = np.load("../data/label_data.npy")

train_data = torch.from_numpy(train_data).float()#.cuda()
label_data = torch.from_numpy(label_data).float()#.cuda()

test_data = np.load("../data/test_data.npy")
test_labels = np.load("../data/test_labels.npy")

test_data = torch.from_numpy(test_data).float()#.cuda()
test_labels = torch.from_numpy(test_labels).float()#.cuda()

input_scaler = load(open('../data/input_scaler.pkl', 'rb'))
output_scaler = load(open('../data/output_scaler.pkl', 'rb'))

print("train data size ", train_data.size())
print("label data size ", label_data.size())
print("has gpu? ", torch.cuda.is_available())





in_size = 8
hidden_size = 32
out_size = 4

loss_fn = torch.nn.MSELoss()
model = nn.Sequential(
    nn.Linear(in_size, hidden_size),
    nn.Tanh(),
    nn.Linear(hidden_size, hidden_size),
    nn.Tanh(),
    nn.Linear(hidden_size, out_size)
)#.cuda()

opt = torch.optim.Adam(model.parameters(), lr=1e-1)

count = 0
def fit(lr, batch_size, epochs):
    global count
    
    for param_group in opt.param_groups:
        param_group['lr'] = lr
    
    for j in range(epochs):
        for i in range(0, train_data.shape[0]-batch_size, batch_size):
            x = train_data[i:i+batch_size, :]
            y = label_data[i:i+batch_size, :]
            
            opt.zero_grad()
            y_hat = model.forward(x)
            loss = loss_fn(y_hat, y)
            loss.backward()
            opt.step()
        plt.scatter(count, loss.item(), color='b')
        count += 1
        print("LOSS", loss)


def test_network(idx):
    yhat = output_scaler.inverse_transform(model.cpu().forward(test_data.cpu()).detach().numpy())
    y_actual = output_scaler.inverse_transform(test_labels.cpu().detach().numpy())
    
    plt.plot(yhat[:,idx])
    plt.plot(y_actual[:,idx])
    plt.show()


def get_evaluation_loss():
    predicted = model.cpu().forward(test_data.cpu()).detach().numpy()
    predicted_force = output_scaler.inverse_transform(predicted)
    actual_force = output_scaler.inverse_transform(test_labels.cpu().detach().numpy())
    print(np.sqrt(np.mean(np.square(predicted_force[:,0] - actual_force[:,0]))))


def test_features():
    test = np.zeros((1,8))
    test[0,0] = .01                 #sinkage
    test[0,1] = .5                  #slip_ratio
    test[0,2] = 0                   #slip_angle
    test[0,3] = 29.76               #kc
    test[0,4] = 2083                #kphi
    test[0,5] = .8                  #n0
    test[0,6] = 0                   #n1
    test[0,7] = .393                #phi

    print(test)
    
    test_norm = input_scaler.transform(test)
    x = torch.from_numpy(test_norm)
    test_out = model.forward(x.float()).detach().numpy()
    test_out = output_scaler.inverse_transform(test_out)
    
    print(test_out)
      
    
def Fx_plot():
    test = np.zeros((100,8))
    test[:,0] = .01
    test[:,1] = np.arange(-1,1,.02) #slip_ratio
    test[:,2] = 0                   #slip_angle
    test[:,3] = 29.76               #kc
    test[:,4] = 2083                #kphi
    test[:,5] = .8                  #n0
    test[:,6] = 0                   #n1
    test[:,7] = 22.5*np.pi/180      #phi
    

    x = torch.from_numpy(test)
    
    test_norm = input_scaler.transform(test)
    x = torch.from_numpy(test_norm)
    test_out = model.forward(x.float()).detach().numpy()
    test_out = output_scaler.inverse_transform(test_out)[:,0]
    

    plt.plot(test[:,1], test_out)
    plt.title("Slip Ratio vs. Longitudinal Force (Fx)")
    plt.xlabel("Slip Ratio")
    plt.ylabel("Logitudinal Force (N)")
    plt.show()

    test = np.zeros((100,8))
    test[:,0] = .02
    test[:,1] = np.arange(-1,1,.02)
    test[:,2] = 0
    test[:,3] = 29.76               #kc
    test[:,4] = 2083                #kphi
    test[:,5] = .8                  #n0
    test[:,6] = 0                   #n1
    test[:,7] = 22.5*np.pi/180      #phi

    x = torch.from_numpy(test)
    
    test_norm = input_scaler.transform(test)
    x = torch.from_numpy(test_norm)
    test_out = model.forward(x.float()).detach().numpy()
    test_out = output_scaler.inverse_transform(test_out)[:,0]
    

    plt.plot(test[:,1], test_out)
    plt.title("Slip Ratio vs. Longitudinal Force (Fx)")
    plt.xlabel("Slip Ratio")
    plt.ylabel("Logitudinal Force (N)")
    plt.show()




def create_plots():
    test = np.zeros((100,8))
    test[:,0] = .0026
    test[:,1] = np.arange(-1,1,.02)
    test[:,2] = 0
    test[:,3] = 29.76               #kc
    test[:,4] = 2083                #kphi
    test[:,5] = .8                  #n0
    test[:,6] = 0                   #n1
    test[:,7] = 22.5*np.pi/180      #phi
    
    
    x = torch.from_numpy(test)
    
    test_norm = input_scaler.transform(test)
    x = torch.from_numpy(test_norm)
    test_out = model.forward(x.float()).detach().numpy()
    test_out = output_scaler.inverse_transform(test_out)[:,0]
    
    plt.plot(test[:,1], test_out)
    plt.title("Slip Ratio vs. Longitudinal Force (Fx)")
    plt.xlabel("Slip Ratio")
    plt.ylabel("Logitudinal Force (N)")
    plt.show()

model_name = "../data/tire_terrain1.net"
md = torch.load(model_name)
model.load_state_dict(md)

#fit(1e-2, 5000, 10)
#fit(1e-4, 5000, 2000)
#fit(1e-4, 500, 100)
#fit(1e-6, 50, 20)
#fit(1e-2, 50, 5)
#fit(1e-3, 50, 100)
#fit(1e-4, 50, 100)
#fit(1e-2, 50, 5)
#fit(1e-3, 50, 100)
#fit(1e-4, 50, 100)
#plt.show()

#test_network(0)
#test_network(1)
#test_network(2)
#test_network(3)
#get_evaluation_loss()

test_features()

#md = model.state_dict()
#print_c_network(md, input_scaler, output_scaler)
#torch.save(md, model_name)
